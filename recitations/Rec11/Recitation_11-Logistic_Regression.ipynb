{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M_sj9n9iJwxh"
   },
   "source": [
    "# Welcome to Recitation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xKP8Pq4mYyM_"
   },
   "source": [
    "## Case Background\n",
    "In this lab, we continue the analysis of the casting problem. Recall that, as part of a longer\n",
    "manufacturing process, a factory needs to cast a large number of rectangular metallic blocks.\n",
    "The blocks are manufactured using a mold, consisting of the main cavity, a cup through\n",
    "which the molten metal is poured, and two risers for cooling. The size and shape of the\n",
    "pouring cup and risers affect how quickly the metal can be poured into the mold, how\n",
    "quickly it cools, and whether it sets correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dh9soj6lKB9_"
   },
   "source": [
    "## Objective\n",
    "The factory needs to cast batches of 100 blocks of size 4.5×4.5×7 inches. The\n",
    "current casting approach is conservative – it takes a long time to pour, but the blocks\n",
    "always set correctly and are usable. Your goal is to achieve a significant reduction in\n",
    "average casting time while still ensuring that most blocks are usable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vUX8BCsRHoxe"
   },
   "source": [
    "## Variables characterizing the mold\n",
    "\n",
    "The following nine mold-variables can be varied:\n",
    "Riser Height, Riser Diameter, Riser 1 Position, Riser 2 Position, Gate Diameter,\n",
    "Cup Height, Sprue Height, Sprue Diameter Bottom, Sprue Diameter Top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yb2ZzEpLJey_"
   },
   "source": [
    "## Data\n",
    "\n",
    "To obtain data on how various mold-variable settings affect pouring and cooling, a batch of 100 is poured with random variations in the nine mold-variables, centered about their baseline values. The data is available in castdata.csv. Use the same file as the previous recitation. As before, the first nine columns are the mold-variables listed above and the 10th column is `BatchTime` and the 11th column is `Feasible`. `Feasible` is 1 if the casting is feasible and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5fjXrHwJlrQ"
   },
   "source": [
    "## ASSIGNMENT\n",
    "\n",
    "This lab project will guide you through the analysis. First, we must import castdata.csv into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CoP3YPMlJj1y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "df = pd.read_csv('castdata.csv')\n",
    "df.head() # view the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EiNj4SFr0QEy"
   },
   "source": [
    "We would like to compare the distributions of the predictors among the two populations, Feasible\n",
    "= 0 and Feasible = 1. The code for doing so is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6Wcy78g4299"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Because pandas won't allow multiple scales for the y-axis,\n",
    "we must divide and conquer with our boxplots. First execute\n",
    "the follwing code to view the boxplots for the variables\n",
    "with the lowest values\n",
    "''' \n",
    "low_vals = ['GateDiam', 'SprueDiamBot', 'SprueDiamTop']\n",
    "\n",
    "df.boxplot(column=low_vals, by = 'Feasible', layout=(2,2), figsize=(10,10))\n",
    "# layout=(2,2) configures how the plots will be outputted into the console\n",
    "# for more info on df.boxplot() head to the link:\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.boxplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5kr2u-kVEW2C"
   },
   "outputs": [],
   "source": [
    "# now do the same for the variables with medium values\n",
    "med_vals = ['CupHeight', 'RiserHeight', 'Riser1Pos', 'Riser2Pos']\n",
    "\n",
    "df.boxplot(column=med_vals, by = 'Feasible', layout=(2,2), figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R4TD65q-EYFx"
   },
   "outputs": [],
   "source": [
    "# finally, do the same for the highest values\n",
    "high_vals = ['SprueHeight', 'RiserDiam']\n",
    "\n",
    "df.boxplot(column=high_vals, by = 'Feasible', layout=(1,2), figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUunmNXXFnRJ"
   },
   "source": [
    "To answer the question below, you will need to know about boxplots. A boxplot uses a box to visualize a collection of observations. In the center of the box is a green line. The height of this line is the median of the observations. The height of the top of the box is 75% quantile (the number such that 75% of the observations are below it). The height of the bottom of the box is the 25% quantile. There are lines coming out of the box (called\n",
    "“whiskers”) that represent the range of values over which most of the data falls. There may be a few circles above and below the whiskers, which are data that fall outside of this range. These points are called “outliers”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sQrOHSOtFZJB"
   },
   "source": [
    "# Question 1\n",
    "Which two or three variables appear most related to Feasible? For those variables, are they higher or lower on average when Feasible = 1 rather than 0. Use these observations to make an initial recommendation about the optimal values of the mold-variables in order to maximize the probability of a feasible casting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pkWC5JzoAicr"
   },
   "source": [
    "Ans: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2crzbZWBsUM8"
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "We will fit a logistic regression model to estimate the probability that a casting is feasible\n",
    "using the mold-variables as predictors. Fit an initial logistic regression model, using the\n",
    "following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ii2BvNF2sYc4"
   },
   "outputs": [],
   "source": [
    "# pull out our dependent/response variable\n",
    "y = df[\"Feasible\"]\n",
    "# slice the df to obtain the desired independent variables \n",
    "# sm.add_constant allows sm.Logit to fit an incercept \n",
    "X = sm.add_constant(df.loc[:, :'Riser2Pos'])\n",
    "# fit the model and return the regression results\n",
    "model = sm.Logit(y, X).fit()\n",
    "results = model.summary()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2RAP_2vu8Hu"
   },
   "source": [
    "The `Logit()` function gives the natural log of the odds that y (\"Feasible\") equals one of the categories (0 or 1). If we were to use the regular values of y, as opposed to $ln(P(Y = y))$, for the response/dependent variable and tried to fit a line, it wouldn’t be a very good representation of the relationship. If you don't believe us, give linear regression a try and see what you find out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vQbzXcdr7d97"
   },
   "source": [
    "# AIC\n",
    "\n",
    "AIC stands for Akaike’s Information Criterion. It estimates the quality of a model, relative to each of other models. The lower AIC score is, the better the model is. Therefore, a model with lowest AIC - in comparison to others, is chosen. Execute the code below to print the AIC value of our current model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnSnW8Sw7nGf"
   },
   "outputs": [],
   "source": [
    "print(f'Current model AIC: {model.aic}')\n",
    "# for those unfamiliar, this is called a Python f-String, it allows you to embed\n",
    "# variables into a string using brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HK35d4GBxPcQ"
   },
   "source": [
    "## Question 2\n",
    "\n",
    "Interpret the summary output: Which variables appear to be statistically\n",
    "significant at the 95% level, and how do they affect feasibility? Do the results from the\n",
    "logistic regression agree or disagree with the results from the boxplots?\n",
    "What is the value of the AIC for this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gUGembJUCy-7"
   },
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_CzwLpFA7fk_"
   },
   "source": [
    "## Minimum AIC\n",
    "\n",
    "We are now going to find a model with the minimum AIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JkUGTyf_zFa0"
   },
   "outputs": [],
   "source": [
    "# this function finds returns a model with the minimum AIC for a logistic regression model\n",
    "def minAIC(X,y):\n",
    "    variables = X.columns\n",
    "    model = sm.Logit(y,X[variables]).fit()\n",
    "    while True:\n",
    "        print(f'old model aic: {model.aic}')\n",
    "        maxp = np.max(model.pvalues)\n",
    "        newvariables = variables[model.pvalues < maxp]\n",
    "        newmodel = sm.Logit(y,X[newvariables]).fit()\n",
    "        print(f'new model aic: {newmodel.aic}')\n",
    "        if newmodel.aic < model.aic:\n",
    "            model = newmodel\n",
    "            variables = newvariables\n",
    "        else:\n",
    "            break\n",
    "    return model,variables\n",
    "\n",
    "#select our features\n",
    "X = sm.add_constant(df.loc[:, :'Riser2Pos'])\n",
    "# now call the minAIC function on our independent and response variables\n",
    "new_model, logit_variables = minAIC(X, y)\n",
    "new_model = sm.Logit(y, X[logit_variables]).fit()\n",
    "results = new_model.summary()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PTKa-LCV4FYH"
   },
   "source": [
    "## Question 3\n",
    "\n",
    "What has changed compared to the previous model? Has the AIC value decreased (check this below)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SRYQlx9O5BWk"
   },
   "outputs": [],
   "source": [
    "# Your code here to check the new_model's AIC value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qa6ENHD9IUez"
   },
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65He_uwhJ7S8"
   },
   "source": [
    "#Multivariate Regression\n",
    "\n",
    "We will now fit a multivariate regression model for batch time using the same variables as predictors.\n",
    "\n",
    "Fit a multivariate regression model, using the code below. \n",
    "\n",
    "Note that in the linear model, all mold-variables are used, though GateDiam is replaced by a cubic polynomial in GateDiam; this model was suggested by the analysis in the previous lab. Additionally, we have used orthogonal polynomials to avoid colinearity. This will allow us to make inferences about the effect of input variables on batch time. You may recall seeing an error warning or colinearity while doing last week's recitation. Remember, colinearity is a concern for inference but not for prediction.  \n",
    "\n",
    "Feasible is not used since it is a response, not a mold-variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5EKU4DYYzVn"
   },
   "outputs": [],
   "source": [
    "#function to produce orthogonal polynomials\n",
    "def ortho_poly_fit(x, degree = 1):\n",
    "    n = degree + 1\n",
    "    x = np.asarray(x).flatten()\n",
    "    if(degree >= len(np.unique(x))):\n",
    "            stop(\"'degree' must be less than number of unique points\")\n",
    "    xbar = np.mean(x)\n",
    "    x = x - xbar\n",
    "    X = np.fliplr(np.vander(x, n))\n",
    "    q,r = np.linalg.qr(X)\n",
    "\n",
    "    z = np.diag(np.diag(r))\n",
    "    raw = np.dot(q, z)\n",
    "\n",
    "    norm2 = np.sum(raw**2, axis=0)\n",
    "    alpha = (np.sum((raw**2)*np.reshape(x,(-1,1)), axis=0)/norm2 + xbar)[:degree]\n",
    "    Z = raw / np.sqrt(norm2)\n",
    "    return Z, norm2, alpha\n",
    "#get degree three orthogonal polynomials for 'GateDiam'\n",
    "Z, norm2, alpha = ortho_poly_fit(df['GateDiam'], degree=3)\n",
    "df2 = pd.DataFrame(Z, columns = ['const', 'GateDiamOrtho', 'GateDiamSq', 'GateDiamCub'])\n",
    "\n",
    "#Construct y and X with all orginal variables, higher order 'GateDiam' terms and a constant term.\n",
    "df2 = pd.DataFrame(Z, columns = ['const', 'GateDiamOrtho', 'GateDiamSq', 'GateDiamCub'])\n",
    "X = sm.add_constant(pd.concat([df.loc[:, 'CupHeight':'Riser2Pos'], df2.loc[:,'GateDiamOrtho':]], axis=1, sort=False))\n",
    "y = df[\"BatchTime\"]\n",
    "\n",
    "linear_model = sm.OLS(y, X).fit()\n",
    "linear_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z4SO7jbyehNM"
   },
   "source": [
    "Run the code below to the linear model and set of variables with minimal AIC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T4KMwSIFgEM6"
   },
   "outputs": [],
   "source": [
    "def minAIC_OLS(X,y):\n",
    "    variables = X.columns\n",
    "    model = sm.OLS(y,X[variables]).fit()\n",
    "    while True:\n",
    "        print(f'old model aic: {model.aic}')\n",
    "        maxp = np.max(model.pvalues)\n",
    "        newvariables = variables[model.pvalues < maxp]\n",
    "        newmodel = sm.OLS(y,X[newvariables]).fit()\n",
    "        print(f'new model aic: {newmodel.aic}')\n",
    "        if newmodel.aic < model.aic:\n",
    "            model = newmodel\n",
    "            variables = newvariables\n",
    "        else:\n",
    "            break\n",
    "    return model,variables\n",
    "new_linear_model , linear_variables = minAIC_OLS(X,y)\n",
    "new_linear_model = sm.OLS(y,X[linear_variables]).fit()\n",
    "results = new_linear_model.summary()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fJDA78s_JtD6"
   },
   "source": [
    "##Question 4\n",
    "What model for predicting BatchTime is selected by minAIC_OLS? Are all variables in that model statistically significant at 0.05?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2f9qAZ5g9ca"
   },
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nh8iYfCjhIT5"
   },
   "source": [
    "Now we will use the logistic model for `Feasible` and the linear model for `BatchTime`, to inform how to set the values of the mold-variables to minimize expected `BatchTime` and maximize $P(`Feasible = 1)$.\n",
    "\n",
    "##Question 5\n",
    "For each of the mold-variables and each of the outcomes $P(Feasible =1)$ and `BatchTime`, state whether increasing the variable would increase the outcome, decrease it, or have no effect, according to the last statistical models that you fit for each.\n",
    "\n",
    "Hint: Consider the following plot to when trying to understand the effect of `GateDiam` on `BatchTime`. The plot shows how $\\beta_{GateDiamOrtho}* X_{GateDiamOrtho} + \\beta_{GateDiamSq}*X_{GateDiamSq}+\\beta_{GateDiamCub}* X_{GateDiamCub}$ changes as `GateDiam` increases.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4UuRRHh9jQTg"
   },
   "outputs": [],
   "source": [
    "GateDiamPoly = X[['GateDiamOrtho','GateDiamSq','GateDiamCub']].dot(new_linear_model.params[['GateDiamOrtho','GateDiamSq','GateDiamCub']])\n",
    "plt.scatter(df['GateDiam'],GateDiamPoly)\n",
    "plt.xlabel('GateDiam')\n",
    "plt.ylabel('GateDiamPoly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3QngtClnheQ5"
   },
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rM2FhtttpJMU"
   },
   "source": [
    "## Question 6\n",
    "Our goal is to set the mold-variables to minimize expected `BatchTime` and\n",
    "maximize $P(Feasible = 1)$. Based on your answers to question 5, for each variable state whether it should be as large as possible, as small as possible, or the value is unknown. For example, if increasing a variable will increase the probability of feasibility and decrease batch time, then it should be as large as possible. If it would increase the probability of feasibility but increase batch time, then the value is unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RrzvFcKzpaEH"
   },
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xy1D-IdVpqkK"
   },
   "source": [
    "# Randomized Search for Better Operating Conditions\n",
    "\n",
    "We now search to find values of the mold-variables that give a low expected `BatchTime` subject to the probability that the casting is feasible being at least 0.95. This problem is best solved by linear programming, but, since linear programming is not a prerequisite for this course, we will use a randomized search.\n",
    "\n",
    "Now we create a new set called newdata with 1,000,000 rows where the predictors vary uniformly between their smallest and largest values in the original data. The responses `BatchTime` and `Feasible` are not included in this data set. Rather, the expected values of `BatchTime` and `Feasible` are predicted using the logistic model and the linear model, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "glC_mJ17wTld"
   },
   "outputs": [],
   "source": [
    "upperbounds = df.loc[:, :'Riser2Pos'].max()\n",
    "lowerbounds = df.loc[:, :'Riser2Pos'].min()\n",
    "N = 1000000\n",
    "np.random.seed(10) \n",
    "newdata = pd.DataFrame()\n",
    "for i in range(9):\n",
    "  newdata[df.columns[i]] = np.random.uniform(lowerbounds[i],upperbounds[i],N)\n",
    "\n",
    "newdata = sm.add_constant(newdata)\n",
    "newdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aicu3qTRDFPE"
   },
   "source": [
    "## Question 7\n",
    "\n",
    "We define the rande of our new data set using the lines:\n",
    "```\n",
    "upperbounds = df.loc[:, :'Riser2Pos'].max()\n",
    "lowerbounds = df.loc[:, :'Riser2Pos'].min()\n",
    "```\n",
    "Why do we define bounds this way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qoKotAXqDevp"
   },
   "source": [
    "Ans:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fk9jwmYozIKe"
   },
   "source": [
    "Next, use `model.predict()` to compute the probability that `Feasible` is equal to 1, and create a sub-dataset called `newdata_feas` of `newdata` where this probability exceeds 0.95. \n",
    "\n",
    "Note: be careful when using `.predict()` for classification problems. Depending on the package it will give the probability of the outcome being 1 or a prediction (0 or 1). For example when using sklearn.LogisiticRegression, `.predict()` gives a 0-1 prediction and `.predict_prob()` gives the probability of the outcome being 1. You will explore sklearns's functionality in homework 8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fA_BbmEuzy8O"
   },
   "outputs": [],
   "source": [
    "#predict probability of feasible block for each data point and remove points \n",
    "#with probability less than 0.95\n",
    "Yhat = new_model.predict(newdata[logit_variables])\n",
    "newdata_feas = newdata[pd.Series(Yhat >= 0.95)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zx_XGXoh2RPu"
   },
   "source": [
    "Now, predict the value of `BatchTime` for all rows of newdata_feas and find the row where `BatchTime` is minimized; this is the single row of the dataset. \n",
    "\n",
    "First we apply the function `ortho_poly_predict` to the `GateDiam` values in our new set so we generate the higher order terms used by the linear regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SrIGR_2-3xu2"
   },
   "outputs": [],
   "source": [
    "def ortho_poly_predict(x, alpha, norm2, degree = 1):\n",
    "    x = np.asarray(x).flatten()\n",
    "    n = degree + 1\n",
    "    Z = np.empty((len(x), n))\n",
    "    Z[:,0] = 1\n",
    "    if degree > 0:\n",
    "        Z[:, 1] = x - alpha[0]\n",
    "    if degree > 1:\n",
    "      for i in np.arange(1,degree):\n",
    "          Z[:, i+1] = (x - alpha[i]) * Z[:, i] - (norm2[i] / norm2[i-1]) * Z[:, i-1]\n",
    "    Z /= np.sqrt(norm2)\n",
    "    return Z\n",
    "\n",
    "Z = ortho_poly_predict(newdata_feas['GateDiam'], alpha, norm2, degree = 3)\n",
    "Z = pd.DataFrame(Z, columns = ['-', 'GateDiamOrtho', 'GateDiamSq', 'GateDiamCub'])\n",
    "#Construct X with all orginal variables, higher order 'GateDiam' terms\n",
    "newdata_feas = newdata_feas.reset_index(drop=True)\n",
    "X = sm.add_constant(pd.concat([newdata_feas.loc[:, 'CupHeight':'Riser2Pos'], Z.loc[:,'GateDiamOrtho':]], axis=1, sort=False))\n",
    "#predict batchtime\n",
    "exBatchTime = new_linear_model.predict(X[variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3MW-8AwHESgY"
   },
   "source": [
    "##Question 8 \n",
    "What is the expected value of BatchTime under optimal conditions? “Optimal\n",
    "conditions” means that the predictors are set to their optimal values.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fz7gLML_15oY"
   },
   "source": [
    "Ans:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P2uaQMkyFIf2"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Huo3hg0b1goU"
   },
   "source": [
    "##Question 9\n",
    "What are the “optimal” values of the variables, where “optimal” means mini-\n",
    "mizing the expected `BatchTime` subject to $P(Feasible = 1) > 0.95$. Compare these results with your answer to Problem 5. You may also want to look at the maximum and minimum values for each variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dm3NUmCoEkzk"
   },
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CD4ThqzCFaS5"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RFBXBMHCEjaQ"
   },
   "source": [
    "##Question 10 \n",
    "\n",
    "What is the probability that Feasible will equal 1 under optimal conditions?\n",
    "Hint: Use predict again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "abOA8aeJFk_H"
   },
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-inbrM8FmAd"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Recitation_11– Logistic_Regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
