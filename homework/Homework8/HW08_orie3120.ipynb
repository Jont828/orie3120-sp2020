{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW08.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"E3nBuI9bRsDo","colab_type":"text"},"source":["#**Homework 8**\n","\n","Due to gradescope May 6 at 2:30pm EST. Please submit an `.ipynb` file.   "]},{"cell_type":"markdown","metadata":{"id":"atnGNmQaR8zJ","colab_type":"text"},"source":["Import packages needed for assignment. Make sure to run this cell first or later cells will not run.\n"]},{"cell_type":"code","metadata":{"id":"tV481OBAR2hq","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import random\n","from sklearn.model_selection import train_test_split \n","from sklearn.linear_model import LinearRegression, LogisticRegression\n","from sklearn.metrics import confusion_matrix, roc_curve"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lW6BJQXpSPM_","colab_type":"text"},"source":["# Problem 1: Logrithmic Regression. \n","To  start, we will practice Logistic Regression on the HW8.csv\n","This CSV file contains three column: X,Y,Z. Create 2 models:\n","-  $P(Z=1|X) = L(β_0 + β_1 X)$\n","-  $P(Y=1|X) = L(β_0 + β_1 X)$\n","\n","a. Load in the data to a pandas DataFrame and construct these two models using `LogisticRegression` from `sklean`. Report the coefficients of both models. \n","\n","You can refer to the documentation here: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n","\n","Hints: \n","- When you first make the `LogisticRegression` variables, make sure to pass in the following:\n","  penalty = 'none'\n","- `LogisticRegression` requires the dependent variables to be a two-dimentional array. If you get an error telling you to reshape your data try `hw8['VarName'].to_numpy().reshape(-1,1)`.\n","- For example creating to create a logistic regession model: `model1 = LogisticRegression(penalty = 'none')`\n","\n","- And to fit the model: `model1.fit(X,Y)` where X may need to be reshaped. "]},{"cell_type":"markdown","metadata":{"id":"AFK_GQ0Nl-EM","colab_type":"text"},"source":["Ans:"]},{"cell_type":"code","metadata":{"id":"QltYWhb7l6OQ","colab_type":"code","colab":{}},"source":["#Your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-ZLsnDvflzrs","colab_type":"text"},"source":["b. Find the predicted $P(Z=1|X)$ when $X=1/2$.\n","\n","NOTE: \n","- predict() function will predict the class label\n","- predict_prob() will predict the probability of both classes with the second entry being for +1. Thus, passing in a vector of size $n$ will output an array of size $n \\times 2$ where the 1st column represents probabilities for the first class and the 2nd column represents probabilities for the other class. Thus, for the first column would be for A=0 and the 2nd for A=1 where A is what you are trying to predict\n"]},{"cell_type":"markdown","metadata":{"id":"_VCow2xMogvA","colab_type":"text"},"source":["Ans:"]},{"cell_type":"code","metadata":{"id":"t0KLiZGpofHw","colab_type":"code","colab":{}},"source":["#Your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FItpyRAdnBVE","colab_type":"text"},"source":["c. find the value of $X$ that maximizes $P(Z=1|X)$, subject to the constraint that $P(Y=1|X) >= 0.8.$  \n","\n","To do this randomly generate 1,000,000 search points from a uniform distribution U over the range $-5 <= X <= 5$ and remove all X which do not satisfy the constaint. Use this smaller set to find the $X$ that maximizes $P(Z=1|X)$. "]},{"cell_type":"markdown","metadata":{"id":"0M7KYzE9p3u-","colab_type":"text"},"source":["Ans:"]},{"cell_type":"code","metadata":{"id":"xlcgsFiRp1wE","colab_type":"code","colab":{}},"source":["#Your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"28bWc8zUS2HW","colab_type":"text"},"source":["##Problem 2: Simple Classification Practice\n","In this example we will fit a logistic regression model and explore some of the functionality built into `sklearn`. We will look at Weather in Australia. This dataset can be found on Kaggle at https://www.kaggle.com/jsphyg/weather-dataset-rattle-package\n","\n","a. First load in the Dataset and display the first 5 rows. Use the pandas command `df.describe()` to display summary statistics such as the mean for each column. "]},{"cell_type":"code","metadata":{"id":"ITF-NZhSrFVu","colab_type":"code","colab":{}},"source":["#Your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"10L5EmkrLQg6","colab_type":"text"},"source":["b. This dataset contains non-numerical columns. For now, filter your data so that you have the following columns:\n","\n","'MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed', 'WindSpeed9am',\n","'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm',\n","'Temp9am', 'Temp3pm', 'RainToday', and 'RainTomorrow'\n","\n","After doing so, remove all data points with empty or NA in any field.\n","you will the pandas function dropna() to be very useful for this\n","Documentation: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n"]},{"cell_type":"code","metadata":{"id":"LU0iAw06rNWT","colab_type":"code","colab":{}},"source":["#Your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4JJ4L0vAWMNf","colab_type":"text"},"source":["c. Before we construct the model, the columns `RainToday` and `RainTomorrow` must be converted to boolean values.\n","\n","Look through the documentation for pandas function replace() use it to replace the strings 'Yes' and 'No' with booleans `True` and `False` in the `RainToday` and `RainTomorrow` columns. \n","https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html\n"]},{"cell_type":"code","metadata":{"id":"zeUgDHHjr4DC","colab_type":"code","colab":{}},"source":["#Your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NJoEZZQQYiip","colab_type":"text"},"source":["d. Now we can create our model. \n","Set up a model that predicts whether it will rain tomorrow.\n","\n","Use train_test_split() to hold out a subset of model evaluation. Hold out 30\\% for the test set and to make things consistent, use the random state of 100. Then build and fit your logistic regression model.\n","\n","Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n","\n","Note: If you see `CovergenceWarming`, try increasing `max_iter` for `LogisticRegression` (e.g. `model =  LogisticRegression(penalty = 'none', max_iter = 1000)')"]},{"cell_type":"code","metadata":{"id":"NKaO4PNjsRGp","colab_type":"code","colab":{}},"source":["#Your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bw5yXo8nc_PJ","colab_type":"text"},"source":["e. After fitting the model, evaluate its performance by using the test set with the function predict. Analyze the True Positive, True Negative, False Positive, and False Negative with the sklearn function confusion_matrix(). Look at its documentation to see how to extract these values.\n","\n","How many True negatives? How many True Positives? How many False Positives? How many False Negatives?\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n"]},{"cell_type":"markdown","metadata":{"id":"M807Ak3wojrw","colab_type":"text"},"source":["Ans:\n"]},{"cell_type":"code","metadata":{"id":"-SSVp6Zgt99L","colab_type":"code","colab":{}},"source":["#Your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i0B2qR0kol4C","colab_type":"text"},"source":["f. There might be cases in the real world where we want to avoid False Positives or False Negatives because they might cost a significant amount of money/time. For example, if we are classifying emails as 'Spam' or 'Not Spam', we may be more worried about an important email getting sent to our spam folder than a few spam emails getting into our inbox.\n","\n","We can account for this by adjusting the threshold to predict in classification. As seen in the lectures, Logistic Regression predicts a probability and we can use that probability to make a real-world choice about the data we are looking at. This is done by deciding where a \"No\" becomes a \"Yes\" for example. We can set a threshold on the probability to achieve this task. By default, model.predict uses a threshold of 0.5. We want to estimate how the threshold values affect prediction error. \n","\n","Test thresholds `[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9].` Use predict_proba() on the test set to calculate FPR (defined below) and TPR (defined below) for each threshold value. Plot with FPR on the X axis and TPR (defined below) on the y axis. \n","\n","FPR = False Positive Rate = $\\frac{False Positive}{False Positive + True Negative}$\n","\n","TPR = True Positive Rate = $\\frac{True Positive}{True Positive + False Negative}$"]},{"cell_type":"code","metadata":{"id":"M6nZAN1Jw02B","colab_type":"code","colab":{}},"source":["#Your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sE4VOE8YvkPi","colab_type":"text"},"source":["g. This is known as an ROC curve. There is also a function for this. Call this function to get vectors `fpr` and `tpr` and plot the curve again\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html"]},{"cell_type":"code","metadata":{"id":"JO3S_zb1yy5X","colab_type":"code","colab":{}},"source":["#Your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yUwJy8rKzqDZ","colab_type":"text"},"source":["h. What would the ROC curve look like for a perfect model? That is a model that correctly predicts whether it rains or not for every entry in the test set. What do you think the ROC curve would look like for a completely random model? That is a model that predicts that it rains tomorrow with probability 0.5 everyday independent of any of the other features?"]},{"cell_type":"markdown","metadata":{"id":"W9nzMH-O1XbJ","colab_type":"text"},"source":["Ans:"]},{"cell_type":"markdown","metadata":{"id":"E-eJigfYSQjb","colab_type":"text"},"source":["#Problem 3: Explore other classification methods in sklearn\n","\n","In sklearn-demo, 10 additional classification methods were introduced. Using the same data as problem 2, predict `RainTomorrow` using `KNeighborsClassifier()`, `RandomForestClassifier()` and `AdaBoostClassifier()` and one additional classifier from the list given in the demo. Compare the performance of your classifiers on the test set defined in problem 3. In particular, which model has the best performance on your testing set? Do you think any of the models are overfitting? How do they compare to the logistic regression model from problem 2?\n","\n","Hints: \n","- These classifiers are in various packages; make sure you import them before trying to build your classifier.\n","- There are three steps to creating each model \n","1. define a model: \n","```\n","mod = classifierName('parameters here')\n","```\n","2. fit the model:\n","```\n","mod.fit(X_train,y_train)\n","```\n","3. test the model:\n","```\n","mod.score(X_test,y_test)\n","```\n","- model.score(X,y) will give you a measure of how well your data, X, using the model explains the output, y. Consider looking at the score for both your training and testing data. What might it mean if the testing score is much lower than the training score?\n","- Some of the classifiers require parameter inputs. You can start by using the same parameter values as used in the demo, but you should also play around with them. e.g. What happens when you set `n_neighbors = 1 ` in the `KNeighborsClassifier`. "]},{"cell_type":"markdown","metadata":{"id":"rG8LWWyuSR6_","colab_type":"text"},"source":["Ans:"]},{"cell_type":"code","metadata":{"id":"V3i-CR40SSyI","colab_type":"code","colab":{}},"source":["#Your code here"],"execution_count":0,"outputs":[]}]}